<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>draw_m3_like_one_of_your_ZnJlbmNoIGdpcmxz</title>
  <style>
    * {
      margin: 0;
      padding: 0;
      box-sizing: border-box;
    }

    body {
      background-color: black;
      min-height: 100vh;
      display: flex;
      justify-content: center;
      align-items: center;
      overflow: hidden;
    }

    #canvas {
      /* Canvas is sized dynamically by JS */
    }

    .error {
      color: red;
      font-family: monospace;
      position: absolute;
      top: 50%;
      left: 50%;
      transform: translate(-50%, -50%);
    }
  </style>
</head>
<body>
  <canvas id="canvas"></canvas>
  <div class="error" id="error" style="display: none;"></div>

  <script>
    // Config
    const DEFAULT_FONT_SIZE = 10;
    const MIN_FONT_SIZE = 4;
    const CHAR_WIDTH_RATIO = 0.6; // Monospace character width ratio for canvas

    const canvas = document.getElementById('canvas');
    const ctx = canvas.getContext('2d', { alpha: false }); // Opaque for performance
    const errorEl = document.getElementById('error');

    let currentImage = null;
    let maxConstraints = null;
    let currentFontSize = DEFAULT_FONT_SIZE;

    // GIF animation state
    let isAnimated = false;
    let frames = [];
    let currentFrameIndex = 0;

    // Current ASCII lines being displayed
    let currentLines = [];
    let numLines = 0;

    // Opacity state - pre-allocated array
    let opacities = [];

    // Pre-calculated constants for opacity mapping
    const MIN_OPACITY = 0.15;
    const OPACITY_RANGE = 0.85; // 1.0 - 0.15
    const INV_128 = 1 / 128;

    // Rendering state
    let needsRedraw = true;
    let renderScheduled = false;

    // Load gallery and store selected image
    async function loadGallery() {
      try {
        const response = await fetch('gallery.json');
        if (!response.ok) throw new Error('gallery.json not found');

        const gallery = await response.json();
        if (!gallery.images || gallery.images.length === 0) {
          throw new Error('no images in gallery');
        }

        const urlParams = new URLSearchParams(window.location.search);
        const imageId = urlParams.get('image');

        if (imageId) {
          currentImage = gallery.images.find(img => img.id === imageId);
          if (!currentImage) {
            console.warn(`Image '${imageId}' not found, selecting random`);
            currentImage = gallery.images[Math.floor(Math.random() * gallery.images.length)];
          }
        } else {
          currentImage = gallery.images[Math.floor(Math.random() * gallery.images.length)];
        }

        return currentImage;
      } catch (err) {
        errorEl.textContent = `failed to load: ${err.message}`;
        errorEl.style.display = 'block';
        console.error('Failed to load ASCII art:', err);
        return null;
      }
    }

    // Calculate optimal font size to fit within constraints
    function calculateFontSize(columns, lines, maxWidth, maxHeight) {
      const fontSizeByWidth = maxWidth / (columns * CHAR_WIDTH_RATIO);
      const fontSizeByHeight = maxHeight / lines;
      return Math.max(MIN_FONT_SIZE, Math.min(DEFAULT_FONT_SIZE, Math.floor(Math.min(fontSizeByWidth, fontSizeByHeight))));
    }

    // Setup canvas and render initial frame
    function renderWithConstraints() {
      if (!currentImage) return;

      isAnimated = Array.isArray(currentImage.frames) && currentImage.frames.length > 0;
      frames = isAnimated ? currentImage.frames : [currentImage.lines];
      currentFrameIndex = 0;

      const columns = currentImage.columns;
      numLines = frames[0].length;

      if (maxConstraints) {
        currentFontSize = calculateFontSize(columns, numLines, maxConstraints.maxWidth, maxConstraints.maxHeight);
      } else {
        const maxWidth = window.innerWidth - 20;
        const maxHeight = window.innerHeight - 20;
        currentFontSize = calculateFontSize(columns, numLines, maxWidth, maxHeight);
      }

      // Initialize opacities array
      opacities = new Array(numLines).fill(MIN_OPACITY);

      // Setup canvas dimensions
      const width = Math.ceil(columns * CHAR_WIDTH_RATIO * currentFontSize);
      const height = numLines * currentFontSize;

      // Set canvas size (accounting for device pixel ratio for sharpness)
      const dpr = window.devicePixelRatio || 1;
      canvas.width = width * dpr;
      canvas.height = height * dpr;
      canvas.style.width = width + 'px';
      canvas.style.height = height + 'px';
      ctx.scale(dpr, dpr);

      // Configure text rendering
      ctx.font = `${currentFontSize}px monospace`;
      ctx.textBaseline = 'top';

      // Store current lines
      currentLines = frames[0];

      // Initial render
      needsRedraw = true;
      scheduleRender();

      // Request resize from orchestrator
      requestResize(columns, numLines);
    }

    // Advance to next frame (for animated GIFs)
    function nextFrame() {
      if (!isAnimated || frames.length <= 1) return;

      currentFrameIndex = (currentFrameIndex + 1) % frames.length;
      currentLines = frames[currentFrameIndex];
      needsRedraw = true;
    }

    // Request parent window to resize
    function requestResize(columns, lines) {
      const width = Math.ceil(columns * CHAR_WIDTH_RATIO * currentFontSize);
      const height = lines * currentFontSize;

      if (window.parent !== window) {
        window.parent.postMessage({ type: 'resize', width, height }, '*');
      }
    }

    // Schedule a render on next animation frame (debounced)
    function scheduleRender() {
      if (renderScheduled) return;
      renderScheduled = true;
      requestAnimationFrame(render);
    }

    // Render all lines to canvas in a single pass
    function render() {
      renderScheduled = false;
      if (!needsRedraw || numLines === 0) return;

      const width = canvas.width / (window.devicePixelRatio || 1);
      const height = canvas.height / (window.devicePixelRatio || 1);

      // Clear canvas with black background
      ctx.fillStyle = 'black';
      ctx.fillRect(0, 0, width, height);

      // Draw each line with its opacity
      for (let i = 0; i < numLines; i++) {
        const opacity = opacities[i];
        // Convert opacity to rgba for better performance than globalAlpha
        const alpha = Math.round(opacity * 255);
        ctx.fillStyle = `rgba(255,255,255,${opacity})`;
        ctx.fillText(currentLines[i], 0, i * currentFontSize);
      }

      needsRedraw = false;
    }

    // Update opacities based on time domain audio data
    function updateOpacities(timeDomainData) {
      if (numLines === 0) return;

      const dataLen = timeDomainData.length;
      const step = (dataLen / numLines) | 0;

      let changed = false;

      for (let i = 0; i < numLines; i++) {
        const sample = timeDomainData[i * step] || 128;

        let deviation = sample - 128;
        if (deviation < 0) deviation = -deviation;

        const newOpacity = MIN_OPACITY + (deviation * INV_128 * OPACITY_RANGE);

        // Always update - canvas redraw is cheap
        if (opacities[i] !== newOpacity) {
          opacities[i] = newOpacity;
          changed = true;
        }
      }

      if (changed) {
        needsRedraw = true;
        scheduleRender();
      }
    }

    // Listen for messages from orchestrator
    window.addEventListener('message', (e) => {
      if (!e.data) return;

      if (e.data.type === 'init') {
        maxConstraints = { maxWidth: e.data.maxWidth, maxHeight: e.data.maxHeight };
        receivingOrchestratorAudio = true;

        // Use pre-loaded image data from orchestrator if provided (instant render)
        if (e.data.imageData) {
          currentImage = e.data.imageData;
          renderWithConstraints();
        } else if (currentImage) {
          // Fallback: use locally loaded image
          renderWithConstraints();
        }
      } else if (e.data.type === 'audio') {
        receivingOrchestratorAudio = true;
        if (e.data.timeDomainData) {
          updateOpacities(e.data.timeDomainData);
        }
        if (e.data.beat && isAnimated) {
          nextFrame();
          scheduleRender();
        }
      }
    });

    // Standalone mode: initialize local audio
    let localAudioInitialized = false;
    let receivingOrchestratorAudio = false;

    async function initLocalAudio() {
      if (localAudioInitialized || receivingOrchestratorAudio) return;

      try {
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        const audioContext = new (window.AudioContext || window.webkitAudioContext)();
        const source = audioContext.createMediaStreamSource(stream);
        const analyser = audioContext.createAnalyser();

        analyser.fftSize = 512;
        source.connect(analyser);

        const dataArray = new Uint8Array(analyser.fftSize);
        let lastUpdateTime = 0;
        const UPDATE_INTERVAL = 33; // ~30fps

        function update(timestamp) {
          if (timestamp - lastUpdateTime >= UPDATE_INTERVAL) {
            analyser.getByteTimeDomainData(dataArray);
            updateOpacities(dataArray);
            lastUpdateTime = timestamp;
          }
          requestAnimationFrame(update);
        }

        localAudioInitialized = true;
        requestAnimationFrame(update);
      } catch (err) {
        console.log('Microphone access denied - waiting for orchestrator audio');
      }
    }

    // Initialize
    async function init() {
      const isStandalone = window.parent === window;

      if (isStandalone) {
        // Standalone mode: load gallery and render
        await loadGallery();
        renderWithConstraints();
      }
      // In orchestrator mode (iframe): wait for init message with imageData
      // The message handler will set currentImage and call renderWithConstraints
    }

    init();

    // Init local audio after delay if not receiving orchestrator audio
    setTimeout(() => {
      if (numLines > 0) {
        initLocalAudio();
      }
    }, 2000);
  </script>
</body>
</html>
