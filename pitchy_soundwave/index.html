<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Sound Waveform Display</title>
  <style>
    * {
      margin: 0;
      padding: 0;
      box-sizing: border-box;
    }

    body {
      background-color: black;
      min-height: 100vh;
      display: flex;
      justify-content: center;
      align-items: center;
    }

    .display {
      display: grid;
      grid-template-columns: repeat(20, 1fr);
      grid-template-rows: repeat(20, 1fr);
      gap: 6px;
    }

    .dot {
      width: 12px;
      height: 12px;
      border-radius: 50%;
      background-color: white;
      opacity: 0.3;
      transition: opacity 0.05s ease;
    }

    .dot.on {
      opacity: 0.9;
    }
  </style>
</head>
<body>
  <div class="display" id="display"></div>

  <script>
    const GRID_SIZE = 20;
    const display = document.getElementById('display');
    const dots = [];

    // Create the 20x20 grid of dots
    for (let y = 0; y < GRID_SIZE; y++) {
      dots[y] = [];
      for (let x = 0; x < GRID_SIZE; x++) {
        const dot = document.createElement('div');
        dot.className = 'dot';
        display.appendChild(dot);
        dots[y][x] = dot;
      }
    }

    // Turn all dots off
    function clearDisplay() {
      for (let y = 0; y < GRID_SIZE; y++) {
        for (let x = 0; x < GRID_SIZE; x++) {
          dots[y][x].classList.remove('on');
        }
      }
    }

    // Draw waveform based on audio data
    function drawWaveform(dataArray) {
      clearDisplay();

      const step = Math.floor(dataArray.length / GRID_SIZE);
      const sensitivity = 3; // Amplify the signal
      let prevY = null;

      for (let x = 0; x < GRID_SIZE; x++) {
        // Get sample value (0-255), center is 128
        const sample = dataArray[x * step];

        // Amplify the deviation from center
        const deviation = (sample - 128) * sensitivity;
        const amplified = 128 + deviation;

        // Clamp to 0-255 range
        const clamped = Math.max(0, Math.min(255, amplified));

        // Convert to grid position (inverted so higher values are at top)
        const y = Math.floor((1 - clamped / 255) * (GRID_SIZE - 1));

        // Light up the dot at this position
        dots[y][x].classList.add('on');

        // Connect to previous dot by filling in the gap
        if (prevY !== null && prevY !== y) {
          const startY = Math.min(prevY, y);
          const endY = Math.max(prevY, y);
          for (let fillY = startY; fillY <= endY; fillY++) {
            dots[fillY][x].classList.add('on');
          }
        }

        prevY = y;
      }
    }

    // Audio settings (standardized)
    const FFT_SIZE = 512;

    // Audio state for cleanup
    let mediaStream = null;
    let audioContext = null;
    let localUpdateInterval = null;

    // External audio (from orchestrator via postMessage)
    let externalAudio = null;
    let lastExternalDraw = 0;
    const EXTERNAL_UPDATE_INTERVAL = 50; // Match standalone update rate

    // Listen for external audio data from orchestrator
    window.addEventListener('message', (e) => {
      if (e.data && e.data.type === 'audio' && e.data.timeDomainData) {
        externalAudio = e.data;
        // Reset background if it was red from failed local init
        document.body.style.backgroundColor = 'black';
        // Stop local update if running (orchestrator will drive updates)
        if (localUpdateInterval) {
          clearInterval(localUpdateInterval);
          localUpdateInterval = null;
        }
        // Throttle external updates to match standalone rate
        const now = performance.now();
        if (now - lastExternalDraw >= EXTERNAL_UPDATE_INTERVAL) {
          lastExternalDraw = now;
          drawWaveform(new Uint8Array(e.data.timeDomainData));
        }
      }
    });

    // Initialize audio
    async function initAudio() {
      try {
        mediaStream = await navigator.mediaDevices.getUserMedia({ audio: true });

        audioContext = new (window.AudioContext || window.webkitAudioContext)();
        const source = audioContext.createMediaStreamSource(mediaStream);
        const analyser = audioContext.createAnalyser();

        analyser.fftSize = FFT_SIZE;
        analyser.smoothingTimeConstant = 0.3;
        source.connect(analyser);

        const dataArray = new Uint8Array(analyser.fftSize);

        function update() {
          // Only update from local audio if not receiving external
          if (!externalAudio) {
            analyser.getByteTimeDomainData(dataArray);
            drawWaveform(dataArray);
          }
        }

        // Update every 50ms (standalone mode)
        localUpdateInterval = setInterval(update, 50);
      } catch (err) {
        console.log('Microphone access denied - will use external audio if available');
        // Don't set red background - external audio may come in
      }
    }

    // Clean up audio stream on window close
    window.addEventListener('beforeunload', () => {
      if (mediaStream) {
        mediaStream.getTracks().forEach(track => track.stop());
      }
      if (audioContext) {
        audioContext.close();
      }
    });

    // Initialize audio on load
    initAudio();
  </script>
</body>
</html>
