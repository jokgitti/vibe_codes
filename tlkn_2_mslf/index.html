<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>tlkn_2_mslf</title>
  <style>
    * {
      margin: 0;
      padding: 0;
      box-sizing: border-box;
    }

    body {
      background: black;
      display: flex;
      justify-content: center;
      min-height: 100vh;
      font-family: 'Courier New', monospace;
    }

    .chat-container {
      width: 100%;
      max-width: 820px;
      height: 100vh;
      display: flex;
      flex-direction: column-reverse;
      overflow: hidden;
      padding: 20px;
      gap: 8px;
      align-content: flex-end;
    }

    .message {
      max-width: 70%;
      padding: 10px 14px;
      border-radius: 18px;
      color: white;
      font-size: 14px;
      line-height: 1.4;
      word-break: break-word;
      flex-shrink: 0;
      transition: opacity 0.5s ease-out;
      will-change: transform, opacity;
    }

    .message.right {
      align-self: flex-end;
      background: #0b84fe;
      border-bottom-right-radius: 4px;
      animation: slideInRight 0.5s cubic-bezier(0.16, 1, 0.3, 1);
      overflow: hidden;
    }

    .message.left {
      align-self: flex-start;
      background: #3a3a3c;
      border-bottom-left-radius: 4px;
      animation: slideInLeft 0.5s cubic-bezier(0.16, 1, 0.3, 1);
      overflow: hidden;
    }

    .message.encoded {
      word-break: break-all;
    }

    @keyframes slideInLeft {
      0% {
        opacity: 0;
        transform: translateX(-30px) scale(0.95);
        max-height: 0;
        margin-bottom: -8px;
        padding-top: 0;
        padding-bottom: 0;
      }
      50% {
        max-height: 200px;
        margin-bottom: 0;
        padding-top: 10px;
        padding-bottom: 10px;
      }
      100% {
        opacity: 1;
        transform: translateX(0) scale(1);
        max-height: 200px;
      }
    }

    @keyframes slideInRight {
      0% {
        opacity: 0;
        transform: translateX(30px) scale(0.95);
        max-height: 0;
        margin-bottom: -8px;
        padding-top: 0;
        padding-bottom: 0;
      }
      50% {
        max-height: 200px;
        margin-bottom: 0;
        padding-top: 10px;
        padding-bottom: 10px;
      }
      100% {
        opacity: 1;
        transform: translateX(0) scale(1);
        max-height: 200px;
      }
    }
  </style>
</head>
<body>
  <div class="chat-container" id="chat"></div>

  <script>
    // Configuration
    const CONFIG = {
      // Beat detection
      BEAT_THRESHOLD: 1.25,      // Volume must be 25% above average to trigger
      BEAT_COOLDOWN: 300,        // ms between messages
      VOLUME_HISTORY_SIZE: 30,   // ~0.5 seconds at 60fps
      MIN_VOLUME: 5,             // Minimum average volume (avoid silence triggering)

      // Display
      FRESH_MESSAGE_COUNT: 2,
      FADE_OVER_MESSAGES: 12,

      // Audio
      FFT_SIZE: 512,
      SAMPLE_RATE: 44100
    }

    // Frequency bands (same as rotating_gliph)
    const BIN_WIDTH = CONFIG.SAMPLE_RATE / CONFIG.FFT_SIZE
    const KICK_HIGH = 150 // Kick drum range upper bound

    // Participant A sentences (right, blue)
    const SENTENCES_A = [
      "Do you ever feel like we're the same person?",
      "I can't stop thinking about it.",
      "What if none of this is real?",
      "Sometimes I forget which one of us is talking.",
      "Are you listening or just waiting to speak?",
      "I think I already know what you'll say.",
      "We've had this conversation before.",
      "The silence between us says everything.",
      "I'm not sure where I end and you begin.",
      "Do you remember when this started?",
      "It's getting harder to tell us apart.",
      "Maybe we should stop pretending.",
      "I hear my thoughts in your voice.",
      "Are we having this conversation or imagining it?",
      "The words feel familiar before I say them.",
      "I wonder if you're really there.",
      "This feels like talking to a mirror.",
      "Do you think anyone else can see us?",
      "I'm starting to question everything.",
      "Maybe silence would be easier."
    ]

    // Participant B sentences (left, grey)
    const SENTENCES_B = [
      "We've always been the same.",
      "I know. I can't either.",
      "Does it matter if it's real?",
      "That's because we are one voice.",
      "Both. Always both.",
      "You do. You always do.",
      "And we'll have it again.",
      "It always has.",
      "There is no end. No beginning.",
      "It never really started.",
      "Maybe that's the point.",
      "Pretending is all we have.",
      "Because they are your thoughts.",
      "Both. Neither. Does it matter?",
      "They've always been yours.",
      "I'm as real as you need me to be.",
      "Mirrors don't lie.",
      "We only exist for each other.",
      "Good. Keep questioning.",
      "But we'd still be here."
    ]

    // Message state
    const messages = [] // { id, participant, text, element }
    let messageId = 0
    let currentTurn = 0 // 0 = A, 1 = B
    let sentenceIndexA = 0
    let sentenceIndexB = 0

    // Audio state
    let audioContext = null
    let analyser = null
    let mediaStream = null
    let frequencyData = null

    // External audio (from orchestrator via postMessage)
    let externalAudio = null

    // Listen for external audio data from orchestrator
    window.addEventListener('message', (e) => {
      if (e.data && e.data.type === 'audio') {
        externalAudio = e.data
        // Initialize frequencyData if needed
        if (e.data.frequencyData && !frequencyData) {
          frequencyData = new Uint8Array(e.data.frequencyData.length)
        }
        if (e.data.frequencyData) {
          frequencyData.set(e.data.frequencyData)
        }
      }
    })

    // Beat detection state
    const volumeHistory = []
    let lastBeatTime = 0

    // DOM
    const chatContainer = document.getElementById('chat')

    // Audio initialization
    async function initAudio() {
      try {
        mediaStream = await navigator.mediaDevices.getUserMedia({ audio: true })
        audioContext = new (window.AudioContext || window.webkitAudioContext)()
        analyser = audioContext.createAnalyser()
        analyser.fftSize = CONFIG.FFT_SIZE
        analyser.smoothingTimeConstant = 0.3

        const source = audioContext.createMediaStreamSource(mediaStream)
        source.connect(analyser)

        frequencyData = new Uint8Array(analyser.frequencyBinCount)
        return true
      } catch (err) {
        console.log('Microphone access denied:', err)
        document.body.style.backgroundColor = '#1a0000'
        return false
      }
    }

    // Cleanup on window close
    window.addEventListener('beforeunload', () => {
      if (mediaStream) mediaStream.getTracks().forEach(t => t.stop())
      if (audioContext) audioContext.close()
    })

    // Volume calculation (frequency domain with kick boost)
    function getVolume() {
      // Use external audio data if available (orchestrator mode)
      if (externalAudio && externalAudio.volume !== undefined) {
        return externalAudio.volume
      }

      // Fallback to local audio (standalone mode)
      if (!analyser) return 0

      analyser.getByteFrequencyData(frequencyData)
      let sum = 0
      const kickEnd = Math.floor(KICK_HIGH / BIN_WIDTH)

      for (let i = 0; i < frequencyData.length; i++) {
        // Boost kick frequencies by 2x
        if (i < kickEnd) {
          sum += frequencyData[i] * 2
        } else {
          sum += frequencyData[i]
        }
      }

      return sum / frequencyData.length
    }

    // Get average volume from history
    function getAverageVolume() {
      if (volumeHistory.length === 0) return 0
      const sum = volumeHistory.reduce((a, b) => a + b, 0)
      return sum / volumeHistory.length
    }

    // Create message DOM element
    function createMessageElement(msg) {
      const div = document.createElement('div')
      div.className = `message ${msg.participant === 'A' ? 'right' : 'left'}`
      div.dataset.id = msg.id
      div.textContent = msg.text
      return div
    }

    // Update message display (encode old ones, decode fresh ones, fade by age)
    function updateMessageDisplays() {
      const total = messages.length

      messages.forEach((msg, index) => {
        const age = total - 1 - index // 0 = newest, higher = older
        const shouldBeEncoded = age >= CONFIG.FRESH_MESSAGE_COUNT
        const isCurrentlyEncoded = msg.element.classList.contains('encoded')

        if (shouldBeEncoded && !isCurrentlyEncoded) {
          msg.element.textContent = btoa(msg.text)
          msg.element.classList.add('encoded')
        } else if (!shouldBeEncoded && isCurrentlyEncoded) {
          msg.element.textContent = msg.text
          msg.element.classList.remove('encoded')
        }

        // Opacity: 1.0 (newest) to 0.2 (oldest), fading over FADE_OVER_MESSAGES
        const ageRatio = Math.min(age / CONFIG.FADE_OVER_MESSAGES, 1)
        const opacity = 1.0 - (ageRatio * 0.8) // 1.0 -> 0.2
        msg.element.style.opacity = opacity
      })
    }

    // Remove messages that are above the viewport
    function cleanupOffscreenMessages() {
      const containerRect = chatContainer.getBoundingClientRect()

      // Check oldest messages first (beginning of array)
      while (messages.length > 0) {
        const oldest = messages[0]
        const rect = oldest.element.getBoundingClientRect()

        // If bottom of message is above top of container, it's offscreen
        if (rect.bottom < containerRect.top) {
          oldest.element.remove()
          messages.shift()
        } else {
          break // Stop checking, rest are visible
        }
      }
    }

    // Add new message
    function addMessage() {
      const participant = currentTurn === 0 ? 'A' : 'B'
      const sentences = participant === 'A' ? SENTENCES_A : SENTENCES_B
      const sentenceIndex = participant === 'A' ? sentenceIndexA : sentenceIndexB

      const msg = {
        id: messageId++,
        participant,
        text: sentences[sentenceIndex],
        element: null
      }

      // Create and insert element at the beginning (will appear at bottom due to column-reverse)
      msg.element = createMessageElement(msg)
      chatContainer.insertBefore(msg.element, chatContainer.firstChild)

      // Add to end of messages array (newest last)
      messages.push(msg)

      // Update sentence index (cycle)
      if (participant === 'A') {
        sentenceIndexA = (sentenceIndexA + 1) % SENTENCES_A.length
      } else {
        sentenceIndexB = (sentenceIndexB + 1) % SENTENCES_B.length
      }

      // Alternate turn
      currentTurn = currentTurn === 0 ? 1 : 0

      // Update all message displays (encode old ones)
      updateMessageDisplays()

      // Clean up messages that scrolled off screen
      cleanupOffscreenMessages()
    }

    // Analyze audio and detect beats
    function analyzeAudio(currentTime) {
      if (!analyser) return

      const volume = getVolume()
      const avgVolume = getAverageVolume()

      // Update volume history
      volumeHistory.push(volume)
      if (volumeHistory.length > CONFIG.VOLUME_HISTORY_SIZE) {
        volumeHistory.shift()
      }

      // Beat detection
      const timeSinceLastBeat = currentTime - lastBeatTime
      if (volume > avgVolume * CONFIG.BEAT_THRESHOLD &&
          timeSinceLastBeat > CONFIG.BEAT_COOLDOWN &&
          avgVolume > CONFIG.MIN_VOLUME) {

        lastBeatTime = currentTime
        addMessage()
      }
    }

    // Animation loop
    function animate(timestamp) {
      analyzeAudio(timestamp)
      requestAnimationFrame(animate)
    }

    // Start
    async function init() {
      await initAudio()
      addMessage() // First message
      requestAnimationFrame(animate)
    }

    init()
  </script>
</body>
</html>
