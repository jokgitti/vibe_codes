<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>tlkn_2_mslf</title>
  <style>
    * {
      margin: 0;
      padding: 0;
      box-sizing: border-box;
    }

    body {
      background: black;
      display: flex;
      justify-content: center;
      min-height: 100vh;
      font-family: 'Courier New', monospace;
    }

    .chat-container {
      width: 100%;
      max-width: 820px;
      height: 100vh;
      display: flex;
      flex-direction: column-reverse;
      overflow: hidden;
      padding: 20px;
      gap: 8px;
      align-content: flex-end;
    }

    .message {
      max-width: 70%;
      padding: 10px 14px;
      border-radius: 18px;
      color: white;
      font-size: 14px;
      line-height: 1.4;
      word-break: break-word;
      flex-shrink: 0;
      transition: opacity 0.5s ease-out;
      will-change: transform, opacity;
    }

    .message.right {
      align-self: flex-end;
      background: #0b84fe;
      border-bottom-right-radius: 4px;
      animation: slideInRight 0.5s cubic-bezier(0.16, 1, 0.3, 1);
      overflow: hidden;
    }

    .message.left {
      align-self: flex-start;
      background: #3a3a3c;
      border-bottom-left-radius: 4px;
      animation: slideInLeft 0.5s cubic-bezier(0.16, 1, 0.3, 1);
      overflow: hidden;
    }

    .message.encoded {
      word-break: break-all;
    }

    @keyframes slideInLeft {
      0% {
        opacity: 0;
        transform: translateX(-30px) scale(0.95);
        max-height: 0;
        margin-bottom: -8px;
        padding-top: 0;
        padding-bottom: 0;
      }
      50% {
        max-height: 200px;
        margin-bottom: 0;
        padding-top: 10px;
        padding-bottom: 10px;
      }
      100% {
        opacity: 1;
        transform: translateX(0) scale(1);
        max-height: 200px;
      }
    }

    @keyframes slideInRight {
      0% {
        opacity: 0;
        transform: translateX(30px) scale(0.95);
        max-height: 0;
        margin-bottom: -8px;
        padding-top: 0;
        padding-bottom: 0;
      }
      50% {
        max-height: 200px;
        margin-bottom: 0;
        padding-top: 10px;
        padding-bottom: 10px;
      }
      100% {
        opacity: 1;
        transform: translateX(0) scale(1);
        max-height: 200px;
      }
    }
  </style>
</head>
<body>
  <div class="chat-container" id="chat"></div>

  <script>
    // Configuration (standardized across all projects)
    const CONFIG = {
      // Beat detection (time-domain volume typically 0-30)
      BEAT_THRESHOLD: 1.3,       // Volume must be 30% above average to trigger
      BEAT_COOLDOWN: 300,        // ms between messages
      VOLUME_HISTORY_SIZE: 30,   // ~0.5 seconds at 60fps
      MIN_VOLUME: 2,             // Minimum average volume (avoid silence triggering)

      // Display
      FRESH_MESSAGE_COUNT: 2,
      FADE_OVER_MESSAGES: 12,

      // Audio
      FFT_SIZE: 512,

      // LLM Service
      LLM_SERVICE_URL: 'http://localhost:3001'
    }

    // Message state
    const messages = [] // { id, participant, text, element }
    let messageId = 0
    let currentTurn = 0 // 0 = A, 1 = B

    // LLM state
    const conversationHistory = [] // strings for /monologue endpoint
    let nextMessage = null         // pre-fetched message
    let isFetching = false         // prevent concurrent fetches

    // ==========================================================================
    // LLM SERVICE
    // ==========================================================================

    async function fetchNextMessage() {
      if (isFetching) return
      isFetching = true

      try {
        const res = await fetch(`${CONFIG.LLM_SERVICE_URL}/monologue`, {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify({ history: conversationHistory })
        })

        if (!res.ok) throw new Error(`LLM service error: ${res.status}`)

        const data = await res.json()
        nextMessage = data.message || '...'
      } catch (err) {
        console.error('[LLM] Fetch failed:', err.message)
        nextMessage = '...'
      } finally {
        isFetching = false
      }
    }

    // Pre-fetch the first message on startup
    async function initLLM() {
      await fetchNextMessage()
    }

    // ==========================================================================
    // EXTERNAL AUDIO (from orchestrator)
    // ==========================================================================

    let externalAudio = null

    window.addEventListener('message', (e) => {
      if (e.data && e.data.type === 'audio') {
        externalAudio = e.data
        document.body.style.backgroundColor = 'black'
        // React to beat from orchestrator
        if (e.data.beat) {
          addMessage()
        }
      }
    })

    // ==========================================================================
    // LOCAL AUDIO (standalone mode)
    // ==========================================================================

    let audioContext = null
    let analyser = null
    let mediaStream = null
    let timeDomainData = null

    // Beat detection (standalone mode only)
    const volumeHistory = []
    let lastBeatTime = 0

    // DOM
    const chatContainer = document.getElementById('chat')

    // Audio initialization
    async function initAudio() {
      try {
        mediaStream = await navigator.mediaDevices.getUserMedia({ audio: true })
        audioContext = new (window.AudioContext || window.webkitAudioContext)()
        analyser = audioContext.createAnalyser()
        analyser.fftSize = CONFIG.FFT_SIZE
        analyser.smoothingTimeConstant = 0.3

        const source = audioContext.createMediaStreamSource(mediaStream)
        source.connect(analyser)

        timeDomainData = new Uint8Array(analyser.fftSize)
        return true
      } catch (err) {
        console.log('Microphone access denied:', err)
        document.body.style.backgroundColor = '#1a0000'
        return false
      }
    }

    // Cleanup on window close
    window.addEventListener('beforeunload', () => {
      if (mediaStream) mediaStream.getTracks().forEach(t => t.stop())
      if (audioContext) audioContext.close()
    })

    // Volume calculation (time-domain analysis)
    function getVolume() {
      // Use external audio data if available (orchestrator mode)
      if (externalAudio && externalAudio.volume !== undefined) {
        return externalAudio.volume
      }

      // Fallback to local audio (standalone mode)
      if (!analyser) return 0

      analyser.getByteTimeDomainData(timeDomainData)
      let sum = 0
      for (let i = 0; i < timeDomainData.length; i++) {
        sum += Math.abs(timeDomainData[i] - 128)
      }
      return sum / timeDomainData.length
    }

    // Get average volume from history
    function getAverageVolume() {
      if (volumeHistory.length === 0) return 0
      const sum = volumeHistory.reduce((a, b) => a + b, 0)
      return sum / volumeHistory.length
    }

    // Create message DOM element
    function createMessageElement(msg) {
      const div = document.createElement('div')
      div.className = `message ${msg.participant === 'A' ? 'right' : 'left'}`
      div.dataset.id = msg.id
      div.textContent = msg.text
      return div
    }

    // Update message display (encode old ones, decode fresh ones, fade by age)
    function updateMessageDisplays() {
      const total = messages.length

      messages.forEach((msg, index) => {
        const age = total - 1 - index // 0 = newest, higher = older
        const shouldBeEncoded = age >= CONFIG.FRESH_MESSAGE_COUNT
        const isCurrentlyEncoded = msg.element.classList.contains('encoded')

        if (shouldBeEncoded && !isCurrentlyEncoded) {
          msg.element.textContent = btoa(msg.text)
          msg.element.classList.add('encoded')
        } else if (!shouldBeEncoded && isCurrentlyEncoded) {
          msg.element.textContent = msg.text
          msg.element.classList.remove('encoded')
        }

        // Opacity: 1.0 (newest) to 0.2 (oldest), fading over FADE_OVER_MESSAGES
        const ageRatio = Math.min(age / CONFIG.FADE_OVER_MESSAGES, 1)
        const opacity = 1.0 - (ageRatio * 0.8) // 1.0 -> 0.2
        msg.element.style.opacity = opacity
      })
    }

    // Remove messages that are above the viewport
    function cleanupOffscreenMessages() {
      const containerRect = chatContainer.getBoundingClientRect()

      // Check oldest messages first (beginning of array)
      while (messages.length > 0) {
        const oldest = messages[0]
        const rect = oldest.element.getBoundingClientRect()

        // If bottom of message is above top of container, it's offscreen
        if (rect.bottom < containerRect.top) {
          oldest.element.remove()
          messages.shift()
        } else {
          break // Stop checking, rest are visible
        }
      }
    }

    // Add new message
    function addMessage() {
      // Ignore beats while fetching - wait for response
      if (!nextMessage) return

      const participant = currentTurn === 0 ? 'A' : 'B'
      const text = nextMessage

      const msg = {
        id: messageId++,
        participant,
        text,
        element: null
      }

      // Create and insert element at the beginning (will appear at bottom due to column-reverse)
      msg.element = createMessageElement(msg)
      chatContainer.insertBefore(msg.element, chatContainer.firstChild)

      // Add to end of messages array (newest last)
      messages.push(msg)

      // Add to conversation history for LLM context
      conversationHistory.push(text)
      // Keep history manageable (last 20 messages)
      if (conversationHistory.length > 20) {
        conversationHistory.shift()
      }

      // Clear current and pre-fetch next message
      nextMessage = null
      fetchNextMessage()

      // Alternate turn
      currentTurn = currentTurn === 0 ? 1 : 0

      // Update all message displays (encode old ones)
      updateMessageDisplays()

      // Clean up messages that scrolled off screen
      cleanupOffscreenMessages()
    }

    // Local beat detection (standalone mode only)
    function analyzeLocalAudio(currentTime) {
      // Skip if using external audio or no local analyser
      if (externalAudio || !analyser) return

      const volume = getVolume()
      const avgVolume = getAverageVolume()

      volumeHistory.push(volume)
      if (volumeHistory.length > CONFIG.VOLUME_HISTORY_SIZE) {
        volumeHistory.shift()
      }

      const timeSinceLastBeat = currentTime - lastBeatTime
      if (volume > avgVolume * CONFIG.BEAT_THRESHOLD &&
          timeSinceLastBeat > CONFIG.BEAT_COOLDOWN &&
          avgVolume > CONFIG.MIN_VOLUME) {
        lastBeatTime = currentTime
        addMessage()
      }
    }

    // Animation loop
    function animate(timestamp) {
      analyzeLocalAudio(timestamp)
      requestAnimationFrame(animate)
    }

    // Start
    async function init() {
      await initAudio()
      await initLLM() // Fetch first message from LLM
      addMessage() // First message
      requestAnimationFrame(animate)
    }

    init()
  </script>
</body>
</html>
